{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55e25b8-3c4c-4cff-bcc0-fc43fb5fec1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/02 16:04:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://15f5b62faacd:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Testando</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9862ec91e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "if 'spark' in locals() or 'spark' in globals():\n",
    "    spark.stop()\n",
    "    \n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Testando\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b869b82b-ee84-4f5a-b57b-cc9c9e6188c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+----------------+\n",
      "| empId|firstName|lastName|             job|\n",
      "+------+---------+--------+----------------+\n",
      "|200001|  Michael|   Scott|Regional Manager|\n",
      "|200002|   Dwight| Schrute|           Sales|\n",
      "|200003|      Jim| Halpert|           Sales|\n",
      "|200004|  Phyllis|   Lapin|           Sales|\n",
      "|200005|  Stanley|  Hudson|           Sales|\n",
      "+------+---------+--------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDict = [\n",
    "    (200001, \"Michael\", \"Scott\", \"Regional Manager\"),\n",
    "    (200002, \"Dwight\", \"Schrute\", \"Sales\"),\n",
    "    (200003, \"Jim\", \"Halpert\", \"Sales\"),\n",
    "    (200004, \"Phyllis\", \"Lapin\", \"Sales\"),\n",
    "    (200005, \"Stanley\", \"Hudson\", \"Sales\"),\n",
    "    (200006, \"Angela\", \"Martin\", \"Accounting\"),\n",
    "    (200007, \"Kevin\", \"Malone\", \"Accounting\"),\n",
    "    (200008, \"Oscar\", \"Martinez\", \"Accounting\"),\n",
    "    (200009, \"Creed\", \"Bratton\", \"Quality Assurance\"),\n",
    "    (200010, \"Meredith\", \"Palmer\", \"Supplier Relations\"),\n",
    "    (200011, \"Pamela\", \"Beesly\", \"Recepctionist\"),\n",
    "    (200012, \"Kelly\", \"Kapoor\", \"Customer Service\"),\n",
    "    (200013, \"Ryan\", \"Howard\", \"Temp\"),\n",
    "    (200014, \"Toby\", \"Flenderson\", \"Human Resources\"),\n",
    "    (200015, \"Darryl\", \"Philbin\", \"Warehouse Foreman\")\n",
    "]\n",
    "\n",
    "df1 = spark.createDataFrame(data = dataDict, schema = [\"empId\", \"firstName\", \"lastName\", \"job\"])\n",
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d47896b-cc6d-4696-a97c-491f30ce4f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func(job):\n",
    "    if job == 'Sales':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4da0ce5-2256-4654-86a6-b0993f0d9103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "udf_func = udf(lambda x: func(x), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba231d8b-3948-4609-a8b1-8a851a86946e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=================================>                       (11 + 8) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+------------------+-----------+\n",
      "| empId|firstName|  lastName|               job|result_func|\n",
      "+------+---------+----------+------------------+-----------+\n",
      "|200001|  Michael|     Scott|  Regional Manager|          0|\n",
      "|200002|   Dwight|   Schrute|             Sales|          1|\n",
      "|200003|      Jim|   Halpert|             Sales|          1|\n",
      "|200004|  Phyllis|     Lapin|             Sales|          1|\n",
      "|200005|  Stanley|    Hudson|             Sales|          1|\n",
      "|200006|   Angela|    Martin|        Accounting|          0|\n",
      "|200007|    Kevin|    Malone|        Accounting|          0|\n",
      "|200008|    Oscar|  Martinez|        Accounting|          0|\n",
      "|200009|    Creed|   Bratton| Quality Assurance|          0|\n",
      "|200010| Meredith|    Palmer|Supplier Relations|          0|\n",
      "|200011|   Pamela|    Beesly|     Recepctionist|          0|\n",
      "|200012|    Kelly|    Kapoor|  Customer Service|          0|\n",
      "|200013|     Ryan|    Howard|              Temp|          0|\n",
      "|200014|     Toby|Flenderson|   Human Resources|          0|\n",
      "|200015|   Darryl|   Philbin| Warehouse Foreman|          0|\n",
      "+------+---------+----------+------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.withColumn('result_func', udf_func(col('job'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b24124-7765-49dd-942a-1641f3859f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
