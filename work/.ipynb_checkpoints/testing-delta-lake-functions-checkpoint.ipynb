{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d11f7f-27c3-4ba3-86ab-28540ea4d054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b15d04bfbdec:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Testando Operações do Delta Lake</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f010c3e3d30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Testando Operações do Delta Lake\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"s3a://warehouse/\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"admin123\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.fast.upload\", \"true\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\\\n",
    "    .config(\"spark.hadoop.javax.jdo.option.ConnectionDriverName\", \"org.postgresql.Driver\")\\\n",
    "    .config(\"spark.hadoop.javax.jdo.option.ConnectionURL\", \"jdbc:postgresql://postgres:5432/metastore_db\")\\\n",
    "    .config(\"spark.hadoop.javax.jdo.option.ConnectionUserName\", \"hive\")\\\n",
    "    .config(\"spark.hadoop.javax.jdo.option.ConnectionPassword\", \"hive123\")\\\n",
    "    .config(\"spark.hadoop.datanucleus.schema.autoCreateAll\", \"true\")\\\n",
    "    .config(\"spark.hadoop.datanucleus.schema.autoCreateTables\", \"true\")\\\n",
    "    .config(\"spark.hadoop.datanucleus.fixedDatastore\", \"false\")\\\n",
    "    .config(\"spark.hadoop.hive.metastore.schema.verification\", \"false\")\\\n",
    "    .config(\"spark.hadoop.hive.metastore.schema.verification.record.version\", \"false\")\\\n",
    "    .config(\"spark.sql.hive.metastore.version\", \"2.3.9\")\\\n",
    "    .config(\"spark.sql.hive.metastore.jars\", \"builtin\")\\\n",
    "    .config(\"spark.sql.hive.metastore.uris\", \"thrift://0.0.0.0:9083\")\\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57318cc-2af1-455b-90f1-c4828e0ff63a",
   "metadata": {},
   "source": [
    "## Criando dados artificiais\n",
    "\n",
    "Vamos criar uma tabela com dados artificiais com base em um dicionário python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce97ec93-6bcd-4d40-a4cc-076884055025",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict = [\n",
    "    (200001, \"Michael\", \"Scott\", \"Regional Manager\"),\n",
    "    (200002, \"Dwight\", \"Schrute\", \"Sales\"),\n",
    "    (200003, \"Jim\", \"Halpert\", \"Sales\"),\n",
    "    (200004, \"Phyllis\", \"Lapin\", \"Sales\"),\n",
    "    (200005, \"Stanley\", \"Hudson\", \"Sales\"),\n",
    "    (200006, \"Angela\", \"Martin\", \"Accounting\"),\n",
    "    (200007, \"Kevin\", \"Malone\", \"Accounting\"),\n",
    "    (200008, \"Oscar\", \"Martinez\", \"Accounting\"),\n",
    "    (200009, \"Creed\", \"Bratton\", \"Quality Assurance\"),\n",
    "    (200010, \"Meredith\", \"Palmer\", \"Supplier Relations\"),\n",
    "    (200011, \"Pamela\", \"Beesly\", \"Recepctionist\"),\n",
    "    (200012, \"Kelly\", \"Kapoor\", \"Customer Service\"),\n",
    "    (200013, \"Ryan\", \"Howard\", \"Temp\"),\n",
    "    (200014, \"Toby\", \"Flenderson\", \"Human Resources\"),\n",
    "    (200015, \"Darryl\", \"Philbin\", \"Warehouse Foreman\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a23386a-2571-4e42-9c36-5d7318e74f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+------------------+\n",
      "| empId|firstName|  lastName|               job|\n",
      "+------+---------+----------+------------------+\n",
      "|200001|  Michael|     Scott|  Regional Manager|\n",
      "|200002|   Dwight|   Schrute|             Sales|\n",
      "|200003|      Jim|   Halpert|             Sales|\n",
      "|200004|  Phyllis|     Lapin|             Sales|\n",
      "|200005|  Stanley|    Hudson|             Sales|\n",
      "|200006|   Angela|    Martin|        Accounting|\n",
      "|200007|    Kevin|    Malone|        Accounting|\n",
      "|200008|    Oscar|  Martinez|        Accounting|\n",
      "|200009|    Creed|   Bratton| Quality Assurance|\n",
      "|200010| Meredith|    Palmer|Supplier Relations|\n",
      "|200011|   Pamela|    Beesly|     Recepctionist|\n",
      "|200012|    Kelly|    Kapoor|  Customer Service|\n",
      "|200013|     Ryan|    Howard|              Temp|\n",
      "|200014|     Toby|Flenderson|   Human Resources|\n",
      "|200015|   Darryl|   Philbin| Warehouse Foreman|\n",
      "+------+---------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.createDataFrame(data = dataDict, schema = [\"empId\", \"firstName\", \"lastName\", \"job\"])\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc3f9a4-6e93-4145-a6af-081ca57466b6",
   "metadata": {},
   "source": [
    "## Criando Tabelas Delta no Data Lake + Metastore\n",
    "\n",
    "Criando o database dundermifflin caso ele não exista em nosso metastore e criar a tabela DELTA employees com os dados que criamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d92df22-cc08-45d6-90dd-c7601dd9c3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando o DATABASE (caso não exista)\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS dundermifflin\")\n",
    "\n",
    "# Dropando as tabelas caso já tenham sido criadas em outra sessão)\n",
    "spark.sql(\"DROP TABLE IF EXISTS dundermifflin.employees\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS dundermifflin.employees_updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad7f181-541c-441d-8ff0-9ead36906d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Escrevendo o conteúdo do DataFrame df1 na tabela delta dundermifflin.employees\n",
    "\n",
    "df1.write \\\n",
    "    .option(\"overwriteSchema\", \"true\")\\\n",
    "    .format(\"delta\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .saveAsTable(\"dundermifflin.employees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d349127-539d-4d6b-a4dd-ef66c4f85709",
   "metadata": {},
   "source": [
    "É possível listar as tabelas dentro de um determinado database através da função abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a05c4ac-dcdd-4095-a592-99f37ebbcd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='employees', database='dundermifflin', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables(dbName = \"dundermifflin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6f35b-30de-415a-a606-2ba41b0c33f8",
   "metadata": {},
   "source": [
    "Ou através do Spark SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c495f6b4-cb76-464a-9215-3d6c76a113fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----------+\n",
      "|    namespace|tableName|isTemporary|\n",
      "+-------------+---------+-----------+\n",
      "|dundermifflin|employees|      false|\n",
      "+-------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN dundermifflin\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63a7ff-caca-4db8-a67b-726b1655f1c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lendo Tabelas Delta diretamente do S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abda23c1-86fa-414b-b061-8c685b578d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+------------------+\n",
      "| empId|firstName|  lastName|               job|\n",
      "+------+---------+----------+------------------+\n",
      "|200001|  Michael|     Scott|  Regional Manager|\n",
      "|200009|    Creed|   Bratton| Quality Assurance|\n",
      "|200010| Meredith|    Palmer|Supplier Relations|\n",
      "|200012|    Kelly|    Kapoor|  Customer Service|\n",
      "|200014|     Toby|Flenderson|   Human Resources|\n",
      "|200015|   Darryl|   Philbin| Warehouse Foreman|\n",
      "|200011|   Pamela|    Beesly|     Recepctionist|\n",
      "|200008|    Oscar|  Martinez|        Accounting|\n",
      "|200006|   Angela|    Martin|        Accounting|\n",
      "|200004|  Phyllis|     Lapin|             Sales|\n",
      "|200005|  Stanley|    Hudson|             Sales|\n",
      "|200007|    Kevin|    Malone|        Accounting|\n",
      "|200002|   Dwight|   Schrute|             Sales|\n",
      "|200003|      Jim|   Halpert|             Sales|\n",
      "|200013|     Ryan|    Howard|              Temp|\n",
      "+------+---------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.format(\"delta\").load(\"s3a://warehouse/dundermifflin.db/employees\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8933f6-0105-4ae0-9193-1a0326b52578",
   "metadata": {},
   "source": [
    "# Lendo Tabelas Delta a partir do Metastore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7880b33d-e6e4-4da5-96ba-009203ca9999",
   "metadata": {},
   "source": [
    "### • Utilizando Spark SQL + Metastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0acb0e-dc9f-4a49-9219-d34a0da3bc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+------------------+\n",
      "| empId|firstName|  lastName|               job|\n",
      "+------+---------+----------+------------------+\n",
      "|200001|  Michael|     Scott|  Regional Manager|\n",
      "|200009|    Creed|   Bratton| Quality Assurance|\n",
      "|200010| Meredith|    Palmer|Supplier Relations|\n",
      "|200012|    Kelly|    Kapoor|  Customer Service|\n",
      "|200014|     Toby|Flenderson|   Human Resources|\n",
      "|200015|   Darryl|   Philbin| Warehouse Foreman|\n",
      "|200011|   Pamela|    Beesly|     Recepctionist|\n",
      "|200008|    Oscar|  Martinez|        Accounting|\n",
      "|200006|   Angela|    Martin|        Accounting|\n",
      "|200004|  Phyllis|     Lapin|             Sales|\n",
      "|200005|  Stanley|    Hudson|             Sales|\n",
      "|200007|    Kevin|    Malone|        Accounting|\n",
      "|200002|   Dwight|   Schrute|             Sales|\n",
      "|200003|      Jim|   Halpert|             Sales|\n",
      "|200013|     Ryan|    Howard|              Temp|\n",
      "+------+---------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.sql(\"SELECT * FROM dundermifflin.employees\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ae341-b7bf-4cc0-851e-f11a1ac17642",
   "metadata": {},
   "source": [
    "### • Utilizando PySpark + Metastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a13b93df-e118-4d03-aae0-85833057c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+------------------+\n",
      "| empId|firstName|  lastName|               job|\n",
      "+------+---------+----------+------------------+\n",
      "|200001|  Michael|     Scott|  Regional Manager|\n",
      "|200009|    Creed|   Bratton| Quality Assurance|\n",
      "|200010| Meredith|    Palmer|Supplier Relations|\n",
      "|200012|    Kelly|    Kapoor|  Customer Service|\n",
      "|200014|     Toby|Flenderson|   Human Resources|\n",
      "|200015|   Darryl|   Philbin| Warehouse Foreman|\n",
      "|200011|   Pamela|    Beesly|     Recepctionist|\n",
      "|200008|    Oscar|  Martinez|        Accounting|\n",
      "|200006|   Angela|    Martin|        Accounting|\n",
      "|200004|  Phyllis|     Lapin|             Sales|\n",
      "|200005|  Stanley|    Hudson|             Sales|\n",
      "|200007|    Kevin|    Malone|        Accounting|\n",
      "|200002|   Dwight|   Schrute|             Sales|\n",
      "|200003|      Jim|   Halpert|             Sales|\n",
      "|200013|     Ryan|    Howard|              Temp|\n",
      "+------+---------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.table(\"dundermifflin.employees\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5fb4e-619a-4e71-a6d5-ce73afd21589",
   "metadata": {},
   "source": [
    "## Atualizando registros na tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83be29c-9914-44d2-8bec-a1bb85b65bb0",
   "metadata": {},
   "source": [
    "Com tabelas Delta podemos atualizar dados diretamente em uma tabela gravada no deu data lake.\n",
    "\n",
    "Vamos atualizar o campo __job__ do empregado __Dwight Schrute__ para __'Assistant To The Regional Manager'__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80e72e4-ca09-44a9-82cd-971396b4ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fbae13-1a6d-4116-ad57-7b9625209ddc",
   "metadata": {},
   "source": [
    "Podemos utilizar PySpark para obter o __empId__ de Dwight e utilizá-lo como chave para alteração do registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae9cf26-59c5-42d9-ad65-13cb80944a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwight_id = df1\\\n",
    "    .select(\"empId\")\\\n",
    "    .where(col('firstName') == 'Dwight')\\\n",
    "    .collect()[0]\\\n",
    "    .__getitem__('empId')\n",
    "dwight_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793799d2-17c6-45e1-b921-db35eb1aedfb",
   "metadata": {},
   "source": [
    "Podemos atualizar o dado diretamente na tabela utilizando as classes do pacote delta.tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff39604b-775f-430e-b81e-a51c8f5e0162",
   "metadata": {},
   "source": [
    "• Utilizando um string SQL formatado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223f8c45-46ec-4f4d-8399-17e03a38a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forName(spark, \"dundermifflin.employees\")\n",
    "#deltaTable= DeltaTable.forPath(spark, \"s3a://warehouse/dundermifflin.db/employees\")\n",
    "\n",
    "deltaTable.update(\n",
    "  condition = f\"empId = {dwight_id}\",\n",
    "  set = {\"job\": \"'Assistant To The Regional Manager'\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef54e06-dfde-4cdc-ae97-ea3ef38e0c6a",
   "metadata": {},
   "source": [
    "• Utilizando funções de Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc820352-0264-465c-982b-a39bbc626432",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forName(spark, \"dundermifflin.employees\")\n",
    "#deltaTable= DeltaTable.forPath(spark, \"s3a://warehouse/dundermifflin.db/employees\")\n",
    "\n",
    "deltaTable.update(\n",
    "  condition = col('empId') == dwight_id,\n",
    "  set = {\"job\": lit('Assistant To The Regional Manager')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ce27cde-bbfc-4f42-8870-546d940d9b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+---------------------------------+\n",
      "|empId |firstName|lastName  |job                              |\n",
      "+------+---------+----------+---------------------------------+\n",
      "|200002|Dwight   |Schrute   |Assistant To The Regional Manager|\n",
      "|200001|Michael  |Scott     |Regional Manager                 |\n",
      "|200009|Creed    |Bratton   |Quality Assurance                |\n",
      "|200010|Meredith |Palmer    |Supplier Relations               |\n",
      "|200012|Kelly    |Kapoor    |Customer Service                 |\n",
      "|200014|Toby     |Flenderson|Human Resources                  |\n",
      "|200015|Darryl   |Philbin   |Warehouse Foreman                |\n",
      "|200011|Pamela   |Beesly    |Recepctionist                    |\n",
      "|200008|Oscar    |Martinez  |Accounting                       |\n",
      "|200006|Angela   |Martin    |Accounting                       |\n",
      "|200004|Phyllis  |Lapin     |Sales                            |\n",
      "|200005|Stanley  |Hudson    |Sales                            |\n",
      "|200007|Kevin    |Malone    |Accounting                       |\n",
      "|200003|Jim      |Halpert   |Sales                            |\n",
      "|200013|Ryan     |Howard    |Temp                             |\n",
      "+------+---------+----------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"dundermifflin.employees\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57efb8ac-686c-4d7d-b53f-84e2257c91d7",
   "metadata": {},
   "source": [
    "## Deletando Registro na tabela\n",
    "\n",
    "Com tabelas Delta podemos deletar dados diretamente em uma tabela gravada no deu data lake.\n",
    "\n",
    "Vamos deletar o empregado __Ryan Howard__ da tabela __Employees__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca0be3-f6f5-40b2-b5c6-4ae39def02c9",
   "metadata": {},
   "source": [
    "Podemos utilizar PySpark para obter o __empId__ de Ryan e utilizá-lo como chave para alteração do registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fe63cec-1169-4fad-9452-95cc5aa0b83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200013"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ryan_id = df1\\\n",
    "    .select(\"empId\")\\\n",
    "    .where( (col('firstName') == 'Ryan') & (col('lastname') == 'Howard') )\\\n",
    "    .collect()[0]\\\n",
    "    .__getitem__('empId')\n",
    "ryan_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d25d970a-2d30-4e31-9465-d17d882e0918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+---------------------------------+\n",
      "|empId |firstName|lastName  |job                              |\n",
      "+------+---------+----------+---------------------------------+\n",
      "|200002|Dwight   |Schrute   |Assistant To The Regional Manager|\n",
      "|200001|Michael  |Scott     |Regional Manager                 |\n",
      "|200009|Creed    |Bratton   |Quality Assurance                |\n",
      "|200010|Meredith |Palmer    |Supplier Relations               |\n",
      "|200012|Kelly    |Kapoor    |Customer Service                 |\n",
      "|200014|Toby     |Flenderson|Human Resources                  |\n",
      "|200015|Darryl   |Philbin   |Warehouse Foreman                |\n",
      "|200011|Pamela   |Beesly    |Recepctionist                    |\n",
      "|200008|Oscar    |Martinez  |Accounting                       |\n",
      "|200006|Angela   |Martin    |Accounting                       |\n",
      "|200004|Phyllis  |Lapin     |Sales                            |\n",
      "|200005|Stanley  |Hudson    |Sales                            |\n",
      "|200007|Kevin    |Malone    |Accounting                       |\n",
      "|200003|Jim      |Halpert   |Sales                            |\n",
      "+------+---------+----------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTable = DeltaTable.forName(spark, \"dundermifflin.employees\")\n",
    "#deltaTable= DeltaTable.forPath(spark, \"s3a://warehouse/dundermifflin.db/employees\")\n",
    "\n",
    "deltaTable.delete(col('empId') == ryan_id)\n",
    "\n",
    "# Pode executar também com string fromatado SQL\n",
    "# deltaTable.delete(f\"empId = {ryan_id}\")\n",
    "\n",
    "spark.read.table(\"dundermifflin.employees\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ecc5c1-3d0e-4199-b980-8a183b431eca",
   "metadata": {},
   "source": [
    "## Executando UPSERTS (Merges)\n",
    "\n",
    "UPSERTS são operações que permitem a escrita e alteração de poucos registros de uma tabela, sem a necessidade de sobrescrever a tabela inteira\n",
    "\n",
    "### UPSERTS = UPDATES + INSERTS. \n",
    "\n",
    "Ao aplicar um UPSERT você insere novos registros e atualiza os registros já existentes em uma tabela alvo, processando apenas os registros necessários.\n",
    "\n",
    "É possível também provocar a deleção de alguns registros ao utilizar essas operações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce29ad-699e-4908-adbf-2adb9ce70e77",
   "metadata": {},
   "source": [
    "Vamos resetar nossa tabela __employees__ para executar todas as alterações novamente usando um UPSERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e10431cd-56f2-4016-8672-22352305c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict = [\n",
    "    (200001, \"Michael\", \"Scott\", \"Regional Manager\"),\n",
    "    (200002, \"Dwight\", \"Schrute\", \"Sales\"),\n",
    "    (200003, \"Jim\", \"Halpert\", \"Sales\"),\n",
    "    (200004, \"Phyllis\", \"Lapin\", \"Sales\"),\n",
    "    (200005, \"Stanley\", \"Hudson\", \"Sales\"),\n",
    "    (200006, \"Angela\", \"Martin\", \"Accounting\"),\n",
    "    (200007, \"Kevin\", \"Malone\", \"Accounting\"),\n",
    "    (200008, \"Oscar\", \"Martinez\", \"Accounting\"),\n",
    "    (200009, \"Creed\", \"Bratton\", \"Quality Assurance\"),\n",
    "    (200010, \"Meredith\", \"Palmer\", \"Supplier Relations\"),\n",
    "    (200011, \"Pamela\", \"Beesly\", \"Recepctionist\"),\n",
    "    (200012, \"Kelly\", \"Kapoor\", \"Customer Service\"),\n",
    "    (200013, \"Ryan\", \"Howard\", \"Temp\"),\n",
    "    (200014, \"Toby\", \"Flenderson\", \"Human Resources\"),\n",
    "    (200015, \"Darryl\", \"Philbin\", \"Warehouse Foreman\")\n",
    "]\n",
    "\n",
    "df1 = spark.createDataFrame(data = dataDict, schema = [\"empId\", \"firstName\", \"lastName\", \"job\"])\n",
    "\n",
    "df1.write \\\n",
    "    .option(\"overwriteSchema\", \"true\")\\\n",
    "    .format(\"delta\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .saveAsTable(\"dundermifflin.employees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02280322-b0d1-47e6-96a2-871112c91f9d",
   "metadata": {},
   "source": [
    "Um UPSERT necessita de dois DataFrames: um __original__ e outro com as __atualizado__\n",
    "\n",
    "Já temos o __original__ armazenado em nosso metastore (tabela employees) , agora precisamos criar um DataFrame com as atualizações que queremos e chamando-o de dfUpdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cac86ac3-ca8d-4c46-a253-0e1ba903021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+------------------+\n",
      "| empId|firstName|  lastName|               job|\n",
      "+------+---------+----------+------------------+\n",
      "|200001|  Michael|     Scott|  Regional Manager|\n",
      "|200009|    Creed|   Bratton| Quality Assurance|\n",
      "|200010| Meredith|    Palmer|Supplier Relations|\n",
      "|200012|    Kelly|    Kapoor|  Customer Service|\n",
      "|200014|     Toby|Flenderson|   Human Resources|\n",
      "|200015|   Darryl|   Philbin| Warehouse Foreman|\n",
      "|200011|   Pamela|    Beesly|     Recepctionist|\n",
      "|200008|    Oscar|  Martinez|        Accounting|\n",
      "|200006|   Angela|    Martin|        Accounting|\n",
      "|200004|  Phyllis|     Lapin|             Sales|\n",
      "|200005|  Stanley|    Hudson|             Sales|\n",
      "|200007|    Kevin|    Malone|        Accounting|\n",
      "|200002|   Dwight|   Schrute|             Sales|\n",
      "|200003|      Jim|   Halpert|             Sales|\n",
      "|200013|     Ryan|    Howard|              Temp|\n",
      "+------+---------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTableUpdates = DeltaTable.forName(spark, \"dundermifflin.employees\")\n",
    "#deltaTableUpdates = DeltaTable.forPath(spark, \"s3a://warehouse/dundermifflin.db/employees\")\n",
    "\n",
    "dfUpdates = deltaTableUpdates.toDF()\n",
    "dfUpdates.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797e4113-3292-429e-b78f-14e4d4f5fc2f",
   "metadata": {},
   "source": [
    "## As alterações que faremos serão:\n",
    "\n",
    "• Alterar os sobrenomes de alguns funcionários\n",
    "\n",
    "• Alterar o cargo de Dwight Schrute para Assistant to the Regional Manager\n",
    "\n",
    "• Criar uma coluna __markedTermination__ que será utilizada como marcador para demissão\n",
    "\n",
    "• Adicionar um funcionário novo na lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "502f7ea4-0cc6-467b-bd7b-88469a4670b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------+---------------------------------+-----------------+\n",
      "|empId |firstName|lastName      |job                              |markedTermination|\n",
      "+------+---------+--------------+---------------------------------+-----------------+\n",
      "|200001|Michael  |Scott         |Regional Manager                 |false            |\n",
      "|200009|Creed    |Bratton       |Quality Assurance                |false            |\n",
      "|200010|Meredith |Palmer        |Supplier Relations               |false            |\n",
      "|200012|Kelly    |Kapoor        |Customer Service                 |false            |\n",
      "|200014|Toby     |Flenderson    |Human Resources                  |false            |\n",
      "|200015|Darryl   |Philbin       |Warehouse Foreman                |false            |\n",
      "|200011|Pamela   |Beesly Halpert|Recepctionist                    |false            |\n",
      "|200008|Oscar    |Martinez      |Accounting                       |false            |\n",
      "|200006|Angela   |Martin        |Accounting                       |false            |\n",
      "|200004|Phyllis  |Lapin Vance   |Sales                            |false            |\n",
      "|200005|Stanley  |Hudson        |Sales                            |false            |\n",
      "|200007|Kevin    |Malone        |Accounting                       |true             |\n",
      "|200002|Dwight   |Schrute       |Assistant to the Regional Manager|false            |\n",
      "|200003|Jim      |Halpert       |Sales                            |false            |\n",
      "|200013|Ryan     |Howard        |Temp                             |false            |\n",
      "+------+---------+--------------+---------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alterando nomes\n",
    "dfUpdates = dfUpdates.withColumn('lastName',\n",
    "                                 when(col('empId') == 200011, 'Beesly Halpert')\n",
    "                                 .when(col('empId') == 200004, 'Lapin Vance')\n",
    "                                 .otherwise(col('lastName')))\n",
    "# Alterando cargos\n",
    "dfUpdates = dfUpdates.withColumn('job',\\\n",
    "                                 when(col('firstName') == 'Dwight', 'Assistant to the Regional Manager')\\\n",
    "                                 .otherwise(col('job')))\n",
    "# Criando um campo novo\n",
    "dfUpdates = dfUpdates.withColumn('markedTermination',\\\n",
    "                                 when(col('firstName') == 'Kevin', True)\\\n",
    "                                 .otherwise(False))\n",
    "\n",
    "dfUpdates.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24d7f225-89a5-41ae-9d99-9e21297ec703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+-----+-----------------+\n",
      "| empId|firstName|lastName|  job|markedTermination|\n",
      "+------+---------+--------+-----+-----------------+\n",
      "|200016|     Andy| Bernard|Sales|            false|\n",
      "+------+---------+--------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newEmp = [\n",
    "    (200016, \"Andy\", \"Bernard\", \"Sales\", False)\n",
    "]\n",
    "\n",
    "dfnewEmp = spark.createDataFrame(data = newEmp, schema = [\"empId\", \"firstName\", \"lastName\", \"job\", \"markedTermination\"])\n",
    "\n",
    "dfnewEmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "401e686a-9991-415d-be88-2da73ac059e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------+---------------------------------+-----------------+\n",
      "|empId |firstName|lastName      |job                              |markedTermination|\n",
      "+------+---------+--------------+---------------------------------+-----------------+\n",
      "|200001|Michael  |Scott         |Regional Manager                 |false            |\n",
      "|200009|Creed    |Bratton       |Quality Assurance                |false            |\n",
      "|200010|Meredith |Palmer        |Supplier Relations               |false            |\n",
      "|200012|Kelly    |Kapoor        |Customer Service                 |false            |\n",
      "|200014|Toby     |Flenderson    |Human Resources                  |false            |\n",
      "|200015|Darryl   |Philbin       |Warehouse Foreman                |false            |\n",
      "|200011|Pamela   |Beesly Halpert|Recepctionist                    |false            |\n",
      "|200008|Oscar    |Martinez      |Accounting                       |false            |\n",
      "|200006|Angela   |Martin        |Accounting                       |false            |\n",
      "|200004|Phyllis  |Lapin Vance   |Sales                            |false            |\n",
      "|200005|Stanley  |Hudson        |Sales                            |false            |\n",
      "|200007|Kevin    |Malone        |Accounting                       |true             |\n",
      "|200002|Dwight   |Schrute       |Assistant to the Regional Manager|false            |\n",
      "|200003|Jim      |Halpert       |Sales                            |false            |\n",
      "|200013|Ryan     |Howard        |Temp                             |false            |\n",
      "|200016|Andy     |Bernard       |Sales                            |false            |\n",
      "+------+---------+--------------+---------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfUpdates = dfUpdates.union(dfnewEmp)\n",
    "\n",
    "dfUpdates.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c62e44-1704-4bc0-af5e-eaf91dccc7da",
   "metadata": {},
   "source": [
    "Essas alterações foram feitas apenas para fins didáticos. Na vida real provavelmente você vai ter mais um batch de alterações armazenado em algum bucket ou tabela e que será necessário processar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "059e7786-7c51-401c-8198-1beb59ad5358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfUpdates.write \\\n",
    "    .option(\"overwriteSchema\", \"true\")\\\n",
    "    .format(\"delta\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .saveAsTable(\"dundermifflin.employees_updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e611611a-0956-4270-9de9-b6167d052e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forName(spark, \"dundermifflin.employees\")\n",
    "\n",
    "deltaTableUpdates = DeltaTable.forName(spark, \"dundermifflin.employees_updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "309b6449-0e52-4a88-ad86-e598f46c95c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------+---------------------------------+\n",
      "|empId |firstName|lastName      |job                              |\n",
      "+------+---------+--------------+---------------------------------+\n",
      "|200001|Michael  |Scott         |Regional Manager                 |\n",
      "|200002|Dwight   |Schrute       |Assistant to the Regional Manager|\n",
      "|200003|Jim      |Halpert       |Sales                            |\n",
      "|200004|Phyllis  |Lapin Vance   |Sales                            |\n",
      "|200005|Stanley  |Hudson        |Sales                            |\n",
      "|200006|Angela   |Martin        |Accounting                       |\n",
      "|200008|Oscar    |Martinez      |Accounting                       |\n",
      "|200009|Creed    |Bratton       |Quality Assurance                |\n",
      "|200010|Meredith |Palmer        |Supplier Relations               |\n",
      "|200011|Pamela   |Beesly Halpert|Recepctionist                    |\n",
      "|200012|Kelly    |Kapoor        |Customer Service                 |\n",
      "|200013|Ryan     |Howard        |Temp                             |\n",
      "|200014|Toby     |Flenderson    |Human Resources                  |\n",
      "|200015|Darryl   |Philbin       |Warehouse Foreman                |\n",
      "|200016|Andy     |Bernard       |Sales                            |\n",
      "+------+---------+--------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTable.alias('original').merge(dfUpdates.alias('updates'), 'original.empId = updates.empId')\\\n",
    "    .whenMatchedDelete(condition = \"updates.markedTermination = true\")\\\n",
    "    .whenMatchedUpdate(condition = \"updates.markedTermination = false\",\n",
    "                       set = \n",
    "                       {\n",
    "                           \"empId\": \"updates.empId\",\n",
    "                           \"firstName\": \"updates.firstName\",\n",
    "                           \"lastName\": \"updates.lastName\",\n",
    "                           \"job\": \"updates.job\"\n",
    "                       }\n",
    "                      ) \\\n",
    "    .whenNotMatchedInsert(values = \n",
    "                          {\n",
    "                              \"empId\": \"updates.empId\",\n",
    "                              \"firstName\": \"updates.firstName\",\n",
    "                              \"lastName\": \"updates.lastName\",\n",
    "                              \"job\": \"updates.job\"\n",
    "                          }\n",
    "                         )\\\n",
    ".execute()\n",
    "\n",
    "spark.read.table(\"dundermifflin.employees\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45baafff-01f8-4302-87cc-ef502f7e5054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|version|          timestamp|userId|userName|           operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "|      5|2022-12-28 01:50:28|  null|    null|               MERGE|{predicate -> (or...|null|    null|     null|          4|  Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n",
      "|      4|2022-12-28 01:50:20|  null|    null|CREATE OR REPLACE...|{isManaged -> tru...|null|    null|     null|          3|  Serializable|        false|{numFiles -> 12, ...|        null|Apache-Spark/3.3....|\n",
      "|      3|2022-12-28 01:50:18|  null|    null|              DELETE|{predicate -> [\"(...|null|    null|     null|          2|  Serializable|        false|{numRemovedFiles ...|        null|Apache-Spark/3.3....|\n",
      "|      2|2022-12-28 01:50:15|  null|    null|              UPDATE|{predicate -> (em...|null|    null|     null|          1|  Serializable|        false|{numRemovedFiles ...|        null|Apache-Spark/3.3....|\n",
      "|      1|2022-12-28 01:50:13|  null|    null|              UPDATE|{predicate -> (em...|null|    null|     null|          0|  Serializable|        false|{numRemovedFiles ...|        null|Apache-Spark/3.3....|\n",
      "|      0|2022-12-28 01:50:07|  null|    null|CREATE OR REPLACE...|{isManaged -> tru...|null|    null|     null|       null|  Serializable|        false|{numFiles -> 12, ...|        null|Apache-Spark/3.3....|\n",
      "+-------+-------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DESCRIBE HISTORY dundermifflin.employees').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6efb1b28-6a89-44b2-bf30-6ff2c2a6c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/delta-io/delta/pull/1255 <- aguardando resolução\n",
    "# spark.sql('SHOW CREATE TABLE dundermifflin.employees').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
